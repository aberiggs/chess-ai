{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import chess\n",
    "import chess.pgn\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = \"lichess_2017-10_dataset.pth\"\n",
    "validation_dataset = \"lichess_2017-08_dataset.pth\"\n",
    "model_path = \"chess_model_fast.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def board_to_tensor(board, color):\n",
    "    \"\"\"\n",
    "    Convert a chess board to a tensor\n",
    "    \"\"\"\n",
    "    # Initialize tensor\n",
    "    tensor = torch.zeros(15, 8, 8)\n",
    "    \n",
    "    # Fill tensor with pieces\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            piece = board.piece_at(chess.square(i, j))\n",
    "            if piece is not None:\n",
    "                piece_type = piece.piece_type\n",
    "                piece_color = piece.color\n",
    "                tensor[piece_type + 6 * (piece_color == color), i, j] = 1\n",
    "    \n",
    "    # Fill tensor with en passant squares\n",
    "    if board.ep_square is not None:\n",
    "        tensor[12, board.ep_square // 8, board.ep_square % 8] = 1\n",
    "    \n",
    "    # Fill tensor with castling rights\n",
    "    white_castle_channel = 13 if color is chess.WHITE else 14\n",
    "    if board.has_kingside_castling_rights(chess.WHITE):\n",
    "        tensor[white_castle_channel, 6, 0] = 1\n",
    "    if board.has_queenside_castling_rights(chess.WHITE):\n",
    "        tensor[white_castle_channel, 2, 0] = 1\n",
    "    if board.has_kingside_castling_rights(chess.BLACK):\n",
    "        tensor[27 - white_castle_channel, 6, 7] = 1\n",
    "    if board.has_queenside_castling_rights(chess.BLACK):\n",
    "        tensor[27 - white_castle_channel, 2, 7] = 1\n",
    "    \n",
    "    return tensor\n",
    "\n",
    "def move_to_index(move) -> int:\n",
    "    \"\"\"\n",
    "    Convert a move to an index\n",
    "    \"\"\"\n",
    "    # Get the coordinates of the move\n",
    "    from_square = move.from_square\n",
    "    to_square = move.to_square\n",
    "    \n",
    "    # Convert the coordinates to the output tensor\n",
    "    from_x, from_y = from_square // 8, from_square % 8\n",
    "    to_x, to_y = to_square // 8, to_square % 8\n",
    "\n",
    "    assert from_x >= 0 and from_x < 8\n",
    "    assert from_y >= 0 and from_y < 8\n",
    "    assert to_x >= 0 and to_x < 8\n",
    "    assert to_y >= 0 and to_y < 8\n",
    "\n",
    "    # 0bjjjkkklllmmm : j=from_x, k=from_y, l=to_x, m=to_y\n",
    "    return (from_x << 9) | (from_y << 6) | (to_x << 3) | (to_y)\n",
    "    # print(\"from_x\", from_x, \"from_y\", from_y, \"to_x\", to_x, \"to_y\", to_y, \"index\", index)\n",
    "    \n",
    "\n",
    "def move_to_output_tensor(move) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert a move to the coordinate in the output tensor (8x8x8x8)\n",
    "    \"\"\"\n",
    "\n",
    "    # output_tensor = torch.zeros(8*8*8*8)\n",
    "    # output_tensor[move_to_index(move)] = 1\n",
    "    return torch.tensor(move_to_index(move))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.fens = []\n",
    "        self.next_moves = []\n",
    "        for sample in data:\n",
    "            self.fens.append(sample['fen'])\n",
    "            self.next_moves.append(sample['next_move'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fens)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        board = chess.Board(self.fens[idx])\n",
    "        color = board.turn\n",
    "        board_tensor = board_to_tensor(board, color)\n",
    "        next_move = move_to_output_tensor(self.next_moves[idx])\n",
    "\n",
    "        sample = {'board': board_tensor, 'next_move': next_move}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing pgn:  /home/azriv/chess-ai/colab/data.pgn\n",
      "[..........]\n",
      "[=.........]\n",
      "[==........]\n",
      "[===.......]\n",
      "[====......]\n",
      "[=====.....]\n",
      "[======....]\n",
      "[=======...]\n",
      "[========..]\n",
      "[=========.]\n",
      "[==========]\n",
      "Extracted 527510 moves from 14124 games\n",
      "Generated a dataset with 527510 samples\n",
      "Saved dataset to /home/azriv/chess-ai/colab/lichess_2017-08_dataset.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import zstandard as zstd\n",
    "\n",
    "def decompress_zstd(in_file, out_file):\n",
    "    with open(in_file, 'rb') as compressed_file:\n",
    "        decomp = zstd.ZstdDecompressor()\n",
    "        with open(out_file, 'wb') as decompressed_file:\n",
    "            decomp.copy_stream(compressed_file, decompressed_file)\n",
    "\n",
    "def extract_data(game) -> list:\n",
    "    data = []\n",
    "    board = game.board()\n",
    "    game_result = game.headers['Result'][0]\n",
    "    if game_result == '1':\n",
    "        winning_color = chess.WHITE\n",
    "    else:\n",
    "        winning_color = chess.BLACK\n",
    "    \n",
    "    for move in game.mainline_moves():\n",
    "        if board.turn == winning_color:\n",
    "            data.append({'fen': board.fen(), 'next_move': move})\n",
    "        board.push(move)\n",
    "    return data\n",
    "\n",
    "def parse_pgn_file(file, max_games = 0) -> list:\n",
    "    data = []\n",
    "    tenths_done = -1\n",
    "    game_count = 0\n",
    "    extracted_game_count = 0\n",
    "    with open(file) as pgn_file:\n",
    "        while True:\n",
    "            game = chess.pgn.read_game(pgn_file)\n",
    "            if game is None: # No more games in file\n",
    "                break \n",
    "            game_count += 1\n",
    "            \n",
    "            white_elo = int(game.headers['WhiteElo'])\n",
    "            black_elo = int(game.headers['BlackElo'])\n",
    "            if white_elo > 2000 or black_elo > 2000:\n",
    "                data += extract_data(game)\n",
    "                extracted_game_count += 1\n",
    "            \n",
    "            if max_games > 0 and tenths_done < (game_count / max_games) * 10:\n",
    "                tenths_done += 1\n",
    "                print(\"[\", end=\"\")\n",
    "                print(\"=\" * tenths_done, end=\"\")\n",
    "                print(\".\" * (10 - tenths_done), end=\"\")\n",
    "                print(\"]\")\n",
    "                \n",
    "            if game_count == max_games:\n",
    "                break\n",
    "\n",
    "    print(f\"Extracted {len(data)} moves from {extracted_game_count} games\")\n",
    "    return data\n",
    "\n",
    "def generate_dataset(pgn_file: str, dst_file: str):\n",
    "    print(\"Parsing pgn: \", os.path.abspath(pgn_file))\n",
    "    data = parse_pgn_file(pgn_file, 100000)\n",
    "\n",
    "    dataset = ChessDataset(data)\n",
    "    print(\"Generated a dataset with\", len(dataset), \"samples\")\n",
    "    torch.save(dataset, dst_file)\n",
    "    print(\"Saved dataset to\", os.path.abspath(dst_file))\n",
    "      \n",
    "compressed_file = \"lichess_2017-08.pgn.zst\" \n",
    "pgn_file = \"data.pgn\"\n",
    "decompress_zstd(compressed_file, \"data.pgn\")\n",
    "dst_file = compressed_file.split(\".\")[0] + \"_dataset.pth\"\n",
    "generate_dataset(pgn_file, dst_file)\n",
    "# remove the pgn file\n",
    "os.remove(pgn_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChessModel, self).__init__()\n",
    "        self.conv_nn_stack = nn.Sequential(\n",
    "            # Convolutional layers\n",
    "            nn.Conv2d(15, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            # Flatten the tensor for the fully connected layers\n",
    "            nn.Flatten(),\n",
    "            # Fully connected layers\n",
    "            nn.Linear(64*8*8, 64*8*8),\n",
    "            nn.ReLU(),\n",
    "            # Output layer\n",
    "            nn.Linear(64*8*8, 8*8*8*8)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.conv_nn_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to train on 7854493 samples\n",
      "DataLoader ready with 30682 batches\n",
      "Performing training using cuda\n",
      "Model will be saved to /home/azriv/chess-ai/colab/chess_model_fast.pth\n",
      "----- STARTING EPOCH 1 -----\n",
      "Training model...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (256x4096 and 8192x4096)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 86\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEarly stopping. Patience limit reached.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     84\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 48\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m best_moves \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_move\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     47\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \n\u001b[0;32m---> 48\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(logits, best_moves)\n\u001b[1;32m     50\u001b[0m training_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 19\u001b[0m, in \u001b[0;36mChessModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 19\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_nn_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (256x4096 and 8192x4096)"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    ds = torch.load(training_dataset, weights_only=False)\n",
    "    print(\"Preparing to train on\", len(ds), \"samples\")\n",
    "\n",
    "    batch_size = 256\n",
    "    dl = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "    print(\"DataLoader ready with\", len(dl), \"batches\")\n",
    "    \n",
    "    vds = torch.load(validation_dataset, weights_only=False)\n",
    "    vdl = DataLoader(vds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    device = (\n",
    "        \"cuda\"\n",
    "        if torch.cuda.is_available()\n",
    "        else \"mps\"\n",
    "        if torch.backends.mps.is_available()\n",
    "        else \"cpu\"\n",
    "    )\n",
    "    print(f\"Performing training using {device}\")\n",
    "\n",
    "    model = ChessModel().to(device)\n",
    "    if os.path.exists(model_path):\n",
    "        model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "    \n",
    "    print(\"Model will be saved to\", os.path.abspath(model_path))\n",
    "\n",
    "    learning_rate = 0.01\n",
    "    epochs = 100;\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    best_loss = float(\"inf\")\n",
    "    patience = 3\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"----- STARTING EPOCH\", epoch + 1, \"-----\")\n",
    "        \n",
    "        print(\"Training model...\")\n",
    "        model.train()\n",
    "        batch_count = 0\n",
    "        training_loss = 0\n",
    "        for batch in dl:\n",
    "            model_input = batch[\"board\"].to(device)\n",
    "            best_moves = batch[\"next_move\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad() \n",
    "            logits = model(model_input)\n",
    "            loss = loss_fn(logits, best_moves)\n",
    "            training_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (batch_count+1) % 500 == 0:\n",
    "                print(f\"[Batch #{batch_count + 1}] Running loss: {training_loss}\")\n",
    "            batch_count += 1\n",
    "        \n",
    "        training_loss /= len(dl)\n",
    "        \n",
    "        print(\"\\nValidating model...\")\n",
    "        model.eval()\n",
    "        validation_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in vdl:\n",
    "                model_input = batch[\"board\"].to(device)\n",
    "                best_moves = batch[\"next_move\"].to(device)\n",
    "                logits = model(model_input)\n",
    "                loss = loss_fn(logits, best_moves)\n",
    "                validation_loss += loss.item()\n",
    "                \n",
    "        validation_loss /= len(vdl)\n",
    "        print(f\"Epoch {epoch + 1} complete. Training loss: {training_loss} - Validation loss: {validation_loss}\")\n",
    "        print(\"----- END OF EPOCH\", epoch + 1, \"-----\\n\")\n",
    "\n",
    "        if validation_loss < best_loss:\n",
    "            print(\"New best model found. Saving...\")\n",
    "            best_loss = validation_loss\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping. Patience limit reached.\")\n",
    "                break\n",
    "\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
