{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import chess\n",
    "import chess.pgn\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = \"lichess_2018-03_dataset.pth\"\n",
    "validation_dataset = \"lichess_2017-03_dataset.pth\"\n",
    "model_path = \"chess_model.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def board_to_tensor(board, color):\n",
    "    \"\"\"\n",
    "    Convert a chess board to a tensor\n",
    "    \"\"\"\n",
    "    # Initialize tensor\n",
    "    tensor = torch.zeros(15, 8, 8)\n",
    "    \n",
    "    # Fill tensor with pieces\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            piece = board.piece_at(chess.square(i, j))\n",
    "            if piece is not None:\n",
    "                piece_type = piece.piece_type\n",
    "                piece_color = piece.color\n",
    "                tensor[piece_type + 6 * (piece_color == color), i, j] = 1\n",
    "    \n",
    "    # Fill tensor with en passant squares\n",
    "    if board.ep_square is not None:\n",
    "        tensor[12, board.ep_square // 8, board.ep_square % 8] = 1\n",
    "    \n",
    "    # Fill tensor with castling rights\n",
    "    white_castle_channel = 13 if color is chess.WHITE else 14\n",
    "    if board.has_kingside_castling_rights(chess.WHITE):\n",
    "        tensor[white_castle_channel, 6, 0] = 1\n",
    "    if board.has_queenside_castling_rights(chess.WHITE):\n",
    "        tensor[white_castle_channel, 2, 0] = 1\n",
    "    if board.has_kingside_castling_rights(chess.BLACK):\n",
    "        tensor[27 - white_castle_channel, 6, 7] = 1\n",
    "    if board.has_queenside_castling_rights(chess.BLACK):\n",
    "        tensor[27 - white_castle_channel, 2, 7] = 1\n",
    "    \n",
    "    return tensor\n",
    "\n",
    "def move_to_index(move) -> int:\n",
    "    \"\"\"\n",
    "    Convert a move to an index\n",
    "    \"\"\"\n",
    "    # Get the coordinates of the move\n",
    "    from_square = move.from_square\n",
    "    to_square = move.to_square\n",
    "    \n",
    "    # Convert the coordinates to the output tensor\n",
    "    from_x, from_y = from_square // 8, from_square % 8\n",
    "    to_x, to_y = to_square // 8, to_square % 8\n",
    "\n",
    "    assert from_x >= 0 and from_x < 8\n",
    "    assert from_y >= 0 and from_y < 8\n",
    "    assert to_x >= 0 and to_x < 8\n",
    "    assert to_y >= 0 and to_y < 8\n",
    "\n",
    "    # 0bjjjkkklllmmm : j=from_x, k=from_y, l=to_x, m=to_y\n",
    "    return (from_x << 9) | (from_y << 6) | (to_x << 3) | (to_y)\n",
    "    # print(\"from_x\", from_x, \"from_y\", from_y, \"to_x\", to_x, \"to_y\", to_y, \"index\", index)\n",
    "    \n",
    "\n",
    "def move_to_output_tensor(move) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert a move to the coordinate in the output tensor (8x8x8x8)\n",
    "    \"\"\"\n",
    "\n",
    "    # output_tensor = torch.zeros(8*8*8*8)\n",
    "    # output_tensor[move_to_index(move)] = 1\n",
    "    return torch.tensor(move_to_index(move))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.fens = []\n",
    "        self.next_moves = []\n",
    "        for sample in data:\n",
    "            self.fens.append(sample['fen'])\n",
    "            self.next_moves.append(sample['next_move'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fens)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        board = chess.Board(self.fens[idx])\n",
    "        color = board.turn\n",
    "        board_tensor = board_to_tensor(board, color)\n",
    "        next_move = move_to_output_tensor(self.next_moves[idx])\n",
    "\n",
    "        sample = {'board': board_tensor, 'next_move': next_move}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing pgn:  /home/sprocket/chess-ai/colab/data.pgn\n",
      "[..........]\n",
      "[=.........]\n",
      "[==........]\n",
      "[===.......]\n",
      "[====......]\n",
      "[=====.....]\n",
      "[======....]\n",
      "[=======...]\n",
      "[========..]\n",
      "[=========.]\n",
      "[==========]\n",
      "Extracted 11183859 moves from 298070 games\n",
      "Generated a dataset with 11183859 samples\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "import zstandard as zstd\n",
    "\n",
    "def decompress_zstd(in_file, out_file):\n",
    "    with open(in_file, 'rb') as compressed_file:\n",
    "        decomp = zstd.ZstdDecompressor()\n",
    "        with open(out_file, 'wb') as decompressed_file:\n",
    "            decomp.copy_stream(compressed_file, decompressed_file)\n",
    "\n",
    "def extract_data(game) -> list:\n",
    "    data = []\n",
    "    board = game.board()\n",
    "    game_result = game.headers['Result'][0]\n",
    "    if game_result == '1':\n",
    "        winning_color = chess.WHITE\n",
    "    else:\n",
    "        winning_color = chess.BLACK\n",
    "    \n",
    "    for move in game.mainline_moves():\n",
    "        if board.turn == winning_color:\n",
    "            data.append({'fen': board.fen(), 'next_move': move})\n",
    "        board.push(move)\n",
    "    return data\n",
    "\n",
    "def parse_pgn_file(file, max_games = 0) -> list:\n",
    "    data = []\n",
    "    tenths_done = -1\n",
    "    game_count = 0\n",
    "    extracted_game_count = 0\n",
    "    with open(file) as pgn_file:\n",
    "        while True:\n",
    "            game = chess.pgn.read_game(pgn_file)\n",
    "            if game is None: # No more games in file\n",
    "                break \n",
    "            game_count += 1\n",
    "            \n",
    "            white_elo = int(game.headers['WhiteElo'])\n",
    "            black_elo = int(game.headers['BlackElo'])\n",
    "            if white_elo > 2000 or black_elo > 2000:\n",
    "                data += extract_data(game)\n",
    "                extracted_game_count += 1\n",
    "            \n",
    "            if max_games > 0 and tenths_done < (game_count / max_games) * 10:\n",
    "                tenths_done += 1\n",
    "                print(\"[\", end=\"\")\n",
    "                print(\"=\" * tenths_done, end=\"\")\n",
    "                print(\".\" * (10 - tenths_done), end=\"\")\n",
    "                print(\"]\")\n",
    "                \n",
    "            if game_count == max_games:\n",
    "                break\n",
    "\n",
    "    print(f\"Extracted {len(data)} moves from {extracted_game_count} games\")\n",
    "    return data\n",
    "\n",
    "def generate_dataset(pgn_file: str, dst_file: str):\n",
    "    print(\"Parsing pgn: \", os.path.abspath(pgn_file))\n",
    "    data = parse_pgn_file(pgn_file, 1500000)\n",
    "\n",
    "    dataset = ChessDataset(data)\n",
    "    print(\"Generated a dataset with\", len(dataset), \"samples\")\n",
    "    torch.save(dataset, dst_file)\n",
    "    print(\"Saved dataset to\", os.path.abspath(dst_file))\n",
    "      \n",
    "compressed_file = \"lichess_2017-07.pgn.zst\" \n",
    "pgn_file = \"data.pgn\"\n",
    "#decompress_zstd(compressed_file, \"data.pgn\")\n",
    "dst_file = compressed_file.split(\".\")[0] + \"_dataset.pth\"\n",
    "generate_dataset(pgn_file, dst_file)\n",
    "# remove the pgn file\n",
    "os.remove(pgn_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChessModel, self).__init__()\n",
    "        self.conv_nn_stack = nn.Sequential(\n",
    "            # Convolutional layers\n",
    "            nn.Conv2d(15, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "\n",
    "            # Flatten the tensor for the fully connected layers\n",
    "            nn.Flatten(),\n",
    "\n",
    "            # Fully connected layers\n",
    "            nn.Linear(256*8*8, 128*8*8),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128*8*8, 128*8*8),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            # Output layer\n",
    "            nn.Linear(128*8*8, 8*8*8*8)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.conv_nn_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to train on 4861476 samples\n",
      "DataLoader ready with 18991 batches\n",
      "Performing training using cuda\n",
      "Model will be saved to /home/sprocket/chess-ai/colab/chess_model.pth\n",
      "----- STARTING EPOCH 1 -----\n",
      "Training model...\n",
      "[Batch #500] Running loss: 3307.399941921234\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 86\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEarly stopping. Patience limit reached.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     84\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 50\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(model_input)\n\u001b[1;32m     49\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(logits, best_moves)\n\u001b[0;32m---> 50\u001b[0m training_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     52\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    ds = torch.load(training_dataset, weights_only=False)\n",
    "    print(\"Preparing to train on\", len(ds), \"samples\")\n",
    "\n",
    "    batch_size = 256\n",
    "    dl = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "    print(\"DataLoader ready with\", len(dl), \"batches\")\n",
    "    \n",
    "    vds = torch.load(validation_dataset, weights_only=False)\n",
    "    vdl = DataLoader(vds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    device = (\n",
    "        \"cuda\"\n",
    "        if torch.cuda.is_available()\n",
    "        else \"mps\"\n",
    "        if torch.backends.mps.is_available()\n",
    "        else \"cpu\"\n",
    "    )\n",
    "    print(f\"Performing training using {device}\")\n",
    "\n",
    "    model = ChessModel().to(device)\n",
    "    if os.path.exists(model_path):\n",
    "        model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "    \n",
    "    print(\"Model will be saved to\", os.path.abspath(model_path))\n",
    "\n",
    "    learning_rate = 0.01\n",
    "    epochs = 100;\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    best_loss = float(\"inf\")\n",
    "    patience = 3\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"----- STARTING EPOCH\", epoch + 1, \"-----\")\n",
    "        \n",
    "        print(\"Training model...\")\n",
    "        model.train()\n",
    "        batch_count = 0\n",
    "        training_loss = 0\n",
    "        for batch in dl:\n",
    "            model_input = batch[\"board\"].to(device)\n",
    "            best_moves = batch[\"next_move\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad() \n",
    "            logits = model(model_input)\n",
    "            loss = loss_fn(logits, best_moves)\n",
    "            training_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (batch_count+1) % 500 == 0:\n",
    "                print(f\"[Batch #{batch_count + 1}] Running loss: {training_loss}\")\n",
    "            batch_count += 1\n",
    "        \n",
    "        training_loss /= len(dl)\n",
    "        \n",
    "        print(\"\\nValidating model...\")\n",
    "        model.eval()\n",
    "        validation_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in vdl:\n",
    "                model_input = batch[\"board\"].to(device)\n",
    "                best_moves = batch[\"next_move\"].to(device)\n",
    "                logits = model(model_input)\n",
    "                loss = loss_fn(logits, best_moves)\n",
    "                validation_loss += loss.item()\n",
    "                \n",
    "        validation_loss /= len(vdl)\n",
    "        print(f\"Epoch {epoch + 1} complete. Training loss: {training_loss} - Validation loss: {validation_loss}\")\n",
    "        print(\"----- END OF EPOCH\", epoch + 1, \"-----\\n\")\n",
    "\n",
    "        if validation_loss < best_loss:\n",
    "            print(\"New best model found. Saving...\")\n",
    "            best_loss = validation_loss\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping. Patience limit reached.\")\n",
    "                break\n",
    "\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
